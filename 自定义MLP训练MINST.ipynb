{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"自定义MLP训练MINST.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOh/SZtX6ffD/XRj614ysuT"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"-b2QIsEuo6m9"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import numpy as np\n","import pandas as pd\n","import torchvision\n","import torchvision.transforms as T\n","import os\n","from torch.utils.data import Dataset,DataLoader,random_split\n","\n","#设定随机种子以复现\n","def set_seed(seed):\n","  np.random.seed(seed)\n","  torch.manual_seed(seed)\n","  if torch.cuda.is_available():\n","    torch.cuda.manual_seed(seed)\n","    torch.cuda.manual_seed_all(seed)\n","    torch.backends.cudnn.determinstic = True\n","    torch.backends.cudnn.benchmark = False\n","\n","set_seed(42)"]},{"cell_type":"code","source":["\"\"\"\n","使用torchvision的MINST数据集\n","\"\"\"\n","trainval_dataset = torchvision.datasets.MNIST('./',True,transform = T.ToTensor(),download=True)\n","\n","train_dataset , val_dataset = random_split(trainval_dataset,[int(0.8*len(trainval_dataset)) , len(trainval_dataset) - int(0.8*len(trainval_dataset))])\n","\n","train_dataloader = DataLoader(train_dataset,batch_size=32,shuffle=True)\n","val_dataloader = DataLoader(val_dataset,batch_size=32,shuffle=False)\n","\n","# \"\"\"\n","# 使用自定义数据集\n","# \"\"\"\n","# class Mydataset(Dataset):\n","#   def __init__(self,path):\n","#     data = pd.read_csv(path,header=None)\n","#     x = data.iloc[:,1:].to_numpy()\n","#     y = data.iloc[:,0].to_numpy()\n","\n","#     self.x = x\n","#     self.y = y\n","  \n","#   def __len__(self):\n","#     return len(self.y)\n","#   def __getitem__(self,idx):\n","#     x , y = self.x[idx] , self.y[idx]\n","#     x = torch.as_tensor(x,dtype=torch.float32).reshape(1,28,28)\n","#     y = torch.as_tensor(y,dtype=torch.int64)\n","#     return x,y\n","    \n","# # 读入数据\n","# path = '/content/sample_data/mnist_train_small.csv'\n","# dataset = Mydataset(path)\n","\n","# train_dataset,val_dataset = random_split(dataset,[int(0.8*len(dataset)) , len(dataset) - int(0.8*len(dataset))] )\n","\n","# print(len(dataset) , len(train_dataset) , len(val_dataset))\n","\n","# train_dataloader = DataLoader(train_dataset,batch_size = 32,shuffle=True)\n","# val_dataloader = DataLoader(val_dataset,batch_size = 32,shuffle=False)\n"],"metadata":{"id":"6M1fsUjOqhZ8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 自己定义一个MLP\n","\n","class MyLinear(nn.Module):\n","  def __init__(self,in_channel,out_channel,bias=True):\n","    super(MyLinear,self).__init__()\n","    self.weight = nn.Parameter(torch.randn(in_channel,out_channel),requires_grad=True)\n","    if bias:\n","      self.bias = nn.Parameter(torch.randn(out_channel),requires_grad=True)\n","    else:\n","      self.bias = None\n","\n","  def forward(self,x):\n","    x = x @ self.weight\n","    if self.bias !=None:\n","      x +=self.bias\n","    return x"],"metadata":{"id":"1cMrSs-_sHdB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class MyModel(nn.Module):\n","  def __init__(self,num_class=10):\n","    super(MyModel,self).__init__()\n","    self.Linear1 = MyLinear(784,1000)  #weight.shape 784 * 1000 ,bias.shape 1000\n","    self.bn = nn.BatchNorm1d(1000)\n","    self.Linear2 = MyLinear(1000,512)  # 1000*2000 +1000\n","    self.bn2 = nn.BatchNorm1d(512)\n","    self.Linear3 = MyLinear(512,num_class) #2000*10 + 10\n","  def forward(self,x):\n","    bs,ch,w,h = x.shape\n","    #32,1,28,28 -> 32，784\n","    x = x.reshape(bs,ch*w*h)\n","    x = F.relu(self.bn(self.Linear1(x)))\n","    x = F.relu(self.bn2(self.Linear2(x)))\n","    x = self.Linear3(x)\n","    return x\n","\n","\n","model = MyModel(10)\n","x = torch.randn(32,1,28,28)\n","model(x).shape"],"metadata":{"id":"3jcCPPv1v4Wz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def sum_param(model):\n","  total_params = 0\n","  for name,param in model.named_parameters():\n","    total_params += np.prod(param.size())\n","    print(name,param.shape)\n","  print(f\"the parameters of the model is {total_params}\")\n","  return total_params\n"],"metadata":{"id":"x9Ok1342x7Cz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sum_param(model)"],"metadata":{"id":"pxB4n8ZJyT8t"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["optimizer = torch.optim.Adam(model.parameters(),lr = 1e-3)\n","device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n","#torch.optim.lr_scheduler.LinearLR(optimizer,1e-3,1e-4,)\n","\n","def train_one_epoch(model,optimizer,train_dataloader,val_dataloader,epoch):\n","  model.train()\n","  losses =[]\n","  model = model.to(device)\n","\n","  for batch_idx,(x,y) in enumerate(train_dataloader):\n","    x,y = x.to(device),y.to(device)\n","\n","    logits = model(x)\n","\n","    loss = F.cross_entropy(logits,y)\n","\n","    losses.append(loss.item())\n","    #清空累计的梯度\n","    optimizer.zero_grad()\n","    #梯度反向传播\n","    loss.backward()\n","    #更新参数\n","    optimizer.step()\n","\n","    if batch_idx % 100 ==0:\n","      print(f'--epoch:{epoch}----------train_loss:{loss.item():7f}-------------')\n","  \n","  #-------------------------验证-----------------------------------#\n","  correct = 0.\n","  val_loss = []\n","  num = len(val_dataloader.dataset)\n","  with torch.no_grad():\n","    for batch_idx,(x,y) in enumerate(val_dataloader):\n","      x,y = x.to(device),y.to(device)\n","\n","      logits = model(x)\n","\n","      loss = F.cross_entropy(logits,y)\n","\n","      val_loss.append(loss.item())\n","\n","      correct += (logits.softmax(-1).argmax(-1) == y).sum()\n","  correct /=num\n","\n","  print(f\"--epoch:{epoch}----val_acc:{correct:7f}-----val_loss:{np.mean(val_loss):7f}\")\n","\n","  #------------------------保存------------------------------------#\n","  if epoch % 2 ==0:\n","    torch.save({\n","        \"model\":model.state_dict(),\n","        \"optim\":optimizer.state_dict(),\n","        \"epoch\":epoch\n","        },f'./val_acc_{correct:3f}_epoch_{epoch}.ckpt')\n","    print(\"a new model saved!\")\n","\n"],"metadata":{"id":"hPYqeqBlv_AP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["epoch = 5\n","for i in range(epoch):\n","  train_one_epoch(model,optimizer,train_dataloader,val_dataloader,i)"],"metadata":{"id":"DbyZva9LwAJs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 读入模型\n","# model = MyModel(10)\n","# checkpoint = torch.load('/content/val_acc_0.974750_epoch_3.ckpt')\n","\n","# model.load_state_dict(checkpoint['model'])"],"metadata":{"id":"LfeSx37VQ2zI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_dataset = Mydataset('/content/sample_data/mnist_test.csv')\n","test_dataloader = DataLoader(test_dataset,batch_size=32,shuffle=False)\n","@torch.no_grad()\n","def predict(model,test_dataloader):\n","  model.eval()\n","  correct = 0.\n","  model = model.to(device)\n","  for batch_idx,(x,y) in enumerate(test_dataloader):\n","      x,y = x.to(device),y.to(device)\n","\n","      logits = model(x)\n","      correct += (logits.softmax(-1).argmax(-1) == y).sum()\n","  correct /=len(test_dataloader.dataset)\n","  print(f'---------test_acc:{correct}-------------')\n","\n","predict(model,test_dataloader)"],"metadata":{"id":"0F5uOu7MwCrI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","iter_dataset = iter(train_dataset)\n","plt.figure(figsize=(25,25))\n","model.eval()\n","with torch.no_grad():\n","  for i in range(36):\n","    x,y = next(iter_dataset)\n","    y = torch.as_tensor(y)\n","    x,y = x.to(device) , y.to(device)\n","    logits = model(x.reshape(1,1,28,28))\n","    pre = logits.softmax(-1).argmax(-1).item()\n","    plt.subplot(6,6,i+1)\n","    plt.imshow(x[0].cpu())\n","    plt.title(f'predict:{pre},label:{y.item()}')\n","plt.show()"],"metadata":{"id":"l__ABcxPNe_g"},"execution_count":null,"outputs":[]}]}