{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "使用pytoch-lightning做kaggle中的手写数字识别.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/karlmaji/pytorch_learning/blob/master/%E4%BD%BF%E7%94%A8pytoch_lightning%E5%81%9Akaggle%E4%B8%AD%E7%9A%84%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97%E8%AF%86%E5%88%AB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2022-02-26T13:56:48.199196Z",
          "iopub.execute_input": "2022-02-26T13:56:48.199472Z",
          "iopub.status.idle": "2022-02-26T13:56:48.207331Z",
          "shell.execute_reply.started": "2022-02-26T13:56:48.199444Z",
          "shell.execute_reply": "2022-02-26T13:56:48.206503Z"
        },
        "trusted": true,
        "id": "pg95Fnj1OSoM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install einops\n",
        "!pip install pytorch-lightning"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-26T13:56:48.209382Z",
          "iopub.execute_input": "2022-02-26T13:56:48.209878Z",
          "iopub.status.idle": "2022-02-26T13:57:05.575195Z",
          "shell.execute_reply.started": "2022-02-26T13:56:48.209839Z",
          "shell.execute_reply": "2022-02-26T13:57:05.574350Z"
        },
        "trusted": true,
        "id": "MMI9ZJDLOSoQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%config Completer.use_jedi = False #kaggle中用于函数提示"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-26T13:57:05.578464Z",
          "iopub.execute_input": "2022-02-26T13:57:05.578691Z",
          "iopub.status.idle": "2022-02-26T13:57:05.592302Z",
          "shell.execute_reply.started": "2022-02-26T13:57:05.578653Z",
          "shell.execute_reply": "2022-02-26T13:57:05.591612Z"
        },
        "trusted": true,
        "id": "IRr94X7nOSoR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from einops import rearrange,reduce #爱因斯坦标识库 可以非常方便地对tensor做reshape\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import random_split\n",
        "import pytorch_lightning as pl\n",
        "# 为了模型训练能够复现 需要设置随机种子\n",
        "# Function for setting the seed\n",
        "def set_seed(seed):\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():  # GPU operation have separate seed\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "\n",
        "set_seed(42)\n",
        "\"\"\"\n",
        "benchmark 参数为True 那么cuda每次都会去测试最优的卷积内核，\\\n",
        "如果模型结构变化不大，那么设置True 会提高训练速度（开始慢后面快）\n",
        "\n",
        "torch.backends.cudnn.deterministic置为True的话，每次返回的卷积算法将\n",
        "是确定的，即默认算法。如果配合上设置 Torch 的随机种子为固定值的话，\n",
        "应该可以保证每次运行网络的时候相同输入的输出是固定的\n",
        "\"\"\"\n",
        "torch.backends.cudnn.determinstic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "#选择加速器\n",
        "device = torch.device(\"cpu\") if not torch.cuda.is_available() else torch.device(\"cuda:0\")\n",
        "print(\"Using device\", device)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-26T13:57:05.594757Z",
          "iopub.execute_input": "2022-02-26T13:57:05.595309Z",
          "iopub.status.idle": "2022-02-26T13:57:08.822188Z",
          "shell.execute_reply.started": "2022-02-26T13:57:05.595248Z",
          "shell.execute_reply": "2022-02-26T13:57:08.821367Z"
        },
        "trusted": true,
        "id": "CTK9qqQnOSoR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# pytorch训练第一步，构建dataset,dataloader。\n",
        "> 1.继承torch.utils.data中的Dataset类,init载入data或路径， len方法需要获取data个数，getitem方法根据索引获取实际数据供给后续的DataLoader使用  \n",
        "\n",
        "> 2.可以使用torch.utils.data 中的 random_split函数对dataset进行分割  \n",
        "\n",
        "> 3.使用torch.utils.data 中的DataLoader 构建DataLoader 使用x,y = next(iter(dataloader)) 查看一个batch的数据"
      ],
      "metadata": {
        "id": "f95WGQLQPoR2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class mydataset(Dataset):\n",
        "    def __init__(self,data_dir,transpose):\n",
        "        data = pd.read_csv(data_dir)\n",
        "        \n",
        "        x= data.drop(columns = 'label')\n",
        "        x= torch.from_numpy(np.array(x)).to(torch.float)\n",
        "        bs,n = x.shape\n",
        "        w = h = int(np.sqrt(n))\n",
        "        self.x = rearrange(x, 'bs (w h) -> bs 1 w h',w = w,h = h)\n",
        "        \n",
        "        y = data['label']\n",
        "        self.y = torch.from_numpy(np.array(y))\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.y)\n",
        "    def __getitem__(self,idx):\n",
        "        return self.x[idx] , self.y[idx]\n",
        "    \n",
        "\n",
        "dataset = mydataset('/kaggle/input/digit-recognizer/train.csv',None)\n",
        "split_size = int(len(dataset) *0.7)\n",
        "train_dataset,val_dataset = random_split(dataset,[split_size ,len(dataset)-split_size])\n",
        "\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset,batch_size=32 ,shuffle =True)\n",
        "val_dataloader = DataLoader(val_dataset,batch_size=32 ,shuffle =False)\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-26T14:01:58.264363Z",
          "iopub.execute_input": "2022-02-26T14:01:58.264627Z",
          "iopub.status.idle": "2022-02-26T14:02:00.579985Z",
          "shell.execute_reply.started": "2022-02-26T14:01:58.264596Z",
          "shell.execute_reply": "2022-02-26T14:02:00.579234Z"
        },
        "trusted": true,
        "id": "uV2Tx8AMOSoS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 第二步 使用pytorch-lightning 构建网络模型\n",
        "> why? pytoch-lightning提供了非常丰富的API，可以简化复杂的网络调参及训练过程，例如使用callback方法在训练中保存最优模型，根据数据集的特征修正网络模型中的层数和每层神经元量等超参数"
      ],
      "metadata": {
        "id": "7rxwma30RaB_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# use pytorch-lightning to build model"
      ],
      "metadata": {
        "id": "mJUt4XkyOSoT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 与传统方法不同，原先需要继承nn.Module类，pytoch-lightning 需要继承自pl.LightningModule类\n",
        "class ConvModel(pl.LightningModule):\n",
        "    # init构建及forward与原先相同\n",
        "    def __init__(self,in_channels):\n",
        "        super(ConvModel,self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels = in_channels, out_channels = 2 * in_channels,kernel_size=(7,7))\n",
        "        self.conv2 = nn.Conv2d(in_channels = 2 * in_channels , out_channels = 4 * in_channels,kernel_size =(3,3))\n",
        "        self.conv3 = nn.Conv2d(in_channels = 4 * in_channels , out_channels = 8 * in_channels,kernel_size =(3,3))\n",
        "        self.conv4 = nn.Conv2d(in_channels = 8 * in_channels , out_channels = 16 * in_channels,kernel_size =(3,3))\n",
        "        self.L1 = nn.Linear(in_features = 4096 ,out_features= 1024)\n",
        "        \n",
        "        self.L2 = nn.Linear(in_features = 1024,out_features=  128)\n",
        "        self.L3 = nn.Linear(in_features = 128,out_features=  10)\n",
        "    def forward(self,x):\n",
        "        bs,c,h,w  = x.shape\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = F.relu(self.conv4(x))\n",
        "        x  = x.reshape(bs,-1)\n",
        "        x = F.relu(self.L1(x))\n",
        "        x = F.relu(self.L2(x))\n",
        "        x = self.L3(x)\n",
        "        return x\n",
        "    #optimizer的构建 包装在Module类中（可以有多个optimizer）\n",
        "    def configure_optimizers(self):\n",
        "        return torch.optim.Adam(self.parameters(), lr=1e-3)\n",
        "    #每一个batch的训练过程 输入为batch，batchidx 需要返回loss\n",
        "    def training_step(self,batch,batch_idx):\n",
        "        x,y = batch\n",
        "        logits =self(x)\n",
        "        loss = F.cross_entropy(logits,y)\n",
        "        self.log(\"train_loss\",loss)\n",
        "        return loss\n",
        "    #每一个batch的验证过程 同train 可以不return\n",
        "    #需要监视的参数 使用self.log()方法播报 这里播报了val_loss \n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        x,y = batch\n",
        "        num = x.shape[0]\n",
        "        logits = self(x)\n",
        "        self.log(\"val_loss\",F.cross_entropy(logits,y))\n",
        "        y_pre = logits.argmax(dim = -1)\n",
        "        correct = torch.eq(y_pre,y).sum().item()\n",
        "        return correct,num\n",
        "    #验证过程中的每一个epoch结束调用下列函数， val_step_outputs 中存储的是每一个验证batch中return的参数的列表\n",
        "    #此处val_step_outputs中每一个元素为（correct,num） 构成的元组\n",
        "    def validation_epoch_end(self, val_step_outputs):\n",
        "        correct_sum = 0\n",
        "        num = 0\n",
        "        for correct,n in val_step_outputs:\n",
        "            correct_sum += correct\n",
        "            num += n\n",
        "        val_acc = correct_sum/num\n",
        "        #播报val_acc\n",
        "        self.log(\"val_acc\",val_acc)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-26T14:02:02.351461Z",
          "iopub.execute_input": "2022-02-26T14:02:02.351749Z",
          "iopub.status.idle": "2022-02-26T14:02:02.366806Z",
          "shell.execute_reply.started": "2022-02-26T14:02:02.351717Z",
          "shell.execute_reply": "2022-02-26T14:02:02.366008Z"
        },
        "trusted": true,
        "id": "pp8q4AqcOSoU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pytorch_lightning.callbacks import ModelCheckpoint\n",
        "#从callbacks 中 导入 checkpoint 用于保存训练中的checkpoint\n",
        "#这里监控了val_acc参数 保存该参数最大的4个模型\n",
        "checkpointCallback = ModelCheckpoint(dirpath='./',\n",
        "                                     filename='{epoch}-{val_acc:.2f}-{val_loss:.2f}',\n",
        "                                    monitor='val_acc',\n",
        "                                    save_top_k = 4)\n",
        "#实例化模型\n",
        "model = ConvModel(1)\n",
        "#实例化训练器\n",
        "trainer = pl.Trainer(gpus=1,callbacks = [checkpointCallback])\n",
        "#喂入数据\n",
        "trainer.fit(model,train_dataloader,val_dataloader)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-26T14:02:04.192157Z",
          "iopub.execute_input": "2022-02-26T14:02:04.192828Z",
          "iopub.status.idle": "2022-02-26T14:07:15.325895Z",
          "shell.execute_reply.started": "2022-02-26T14:02:04.192780Z",
          "shell.execute_reply": "2022-02-26T14:07:15.325133Z"
        },
        "trusted": true,
        "id": "rTIP0vQFOSoV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# 以上为训练过程"
      ],
      "metadata": {
        "id": "PI5jbsvJT5mp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#训练完成，载入val_acc 最优的模型 用于test\n",
        "model.load_from_checkpoint(\"./epoch=31-val_acc=0.97-val_loss=0.22.ckpt\",in_channels = 1)\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-26T14:09:25.495853Z",
          "iopub.execute_input": "2022-02-26T14:09:25.496481Z",
          "iopub.status.idle": "2022-02-26T14:09:25.557078Z",
          "shell.execute_reply.started": "2022-02-26T14:09:25.496442Z",
          "shell.execute_reply": "2022-02-26T14:09:25.556388Z"
        },
        "trusted": true,
        "id": "cRnLkV3eOSoW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#定义预测函数，（看官方文档也可以放入model中的方法）\n",
        "def predict(model,test_dir,output_dir):\n",
        "    test_data = pd.read_csv(test_dir)\n",
        "    x= torch.from_numpy(np.array(test_data)).to(torch.float)\n",
        "    bs,n = x.shape\n",
        "    w = h = int(np.sqrt(n))\n",
        "    x = rearrange(x, 'bs (w h) -> bs 1 w h',w = w,h = h)\n",
        "    x = rearrange(x,'bs 1 w h -> bs 1 1 w h')\n",
        "    \n",
        "    \n",
        "    model = model.to(device)\n",
        "    x = x.to(device)\n",
        "    y_pre_ls =[]\n",
        "    for i in range(x.shape[0]):\n",
        "        logits = model(x[i])\n",
        "        y_pre = logits.argmax(dim=-1)\n",
        "        y_pre_ls.append((i,y_pre.item()))\n",
        "    with open(output_dir,'w+') as f:\n",
        "        f.write(f'ImageId,Label\\n')\n",
        "        for index,y in y_pre_ls:\n",
        "            f.write(f'{index+1},{y}\\n')\n",
        "            \n",
        "#对测试集进行预测并产生需要提交的文件格式            \n",
        "predict(model,\"../input/digit-recognizer/test.csv\",\"/kaggle/working/result.csv\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-26T14:11:12.113765Z",
          "iopub.execute_input": "2022-02-26T14:11:12.114223Z",
          "iopub.status.idle": "2022-02-26T14:11:33.239778Z",
          "shell.execute_reply.started": "2022-02-26T14:11:12.114184Z",
          "shell.execute_reply": "2022-02-26T14:11:33.239003Z"
        },
        "trusted": true,
        "id": "t69dUHyhOSoW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# 下面是使用传统的方法构建模型和训练过程"
      ],
      "metadata": {
        "id": "mWxTiDmVRQKf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvModel(nn.Module):\n",
        "    def __init__(self,in_channels):\n",
        "        super(ConvModel,self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels = in_channels, out_channels = 2 * in_channels,kernel_size=(7,7))\n",
        "        self.conv2 = nn.Conv2d(in_channels = 2 * in_channels , out_channels = 4 * in_channels,kernel_size =(3,3))\n",
        "        self.conv3 = nn.Conv2d(in_channels = 4 * in_channels , out_channels = 8 * in_channels,kernel_size =(3,3))\n",
        "        self.conv4 = nn.Conv2d(in_channels = 8 * in_channels , out_channels = 16 * in_channels,kernel_size =(3,3))\n",
        "        self.L1 = nn.Linear(in_features = 4096 ,out_features= 512)\n",
        "        self.L2 = nn.Linear(in_features = 512 ,out_features=  10)\n",
        "    def forward(self,x):\n",
        "        bs,c,h,w  = x.shape\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = F.relu(self.conv4(x))\n",
        "        x  = x.reshape(bs,-1)\n",
        "        x = F.relu(self.L1(x))\n",
        "        x = self.L2(x)\n",
        "        return x\n",
        "    \n",
        "        \n",
        "model = ConvModel(1)\n",
        "\n",
        "parameters_num = 0\n",
        "for x,m in model.named_parameters():\n",
        "    parameters_num += m.numel()\n",
        "    \n",
        "print(parameters_num)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-26T12:21:11.532142Z",
          "iopub.execute_input": "2022-02-26T12:21:11.532592Z",
          "iopub.status.idle": "2022-02-26T12:21:11.595759Z",
          "shell.execute_reply.started": "2022-02-26T12:21:11.532545Z",
          "shell.execute_reply": "2022-02-26T12:21:11.594939Z"
        },
        "trusted": true,
        "id": "B9qixifjOSoX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(params=model.parameters(),lr=1e-3)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-26T12:21:18.152539Z",
          "iopub.execute_input": "2022-02-26T12:21:18.153305Z",
          "iopub.status.idle": "2022-02-26T12:21:18.159089Z",
          "shell.execute_reply.started": "2022-02-26T12:21:18.153259Z",
          "shell.execute_reply": "2022-02-26T12:21:18.158166Z"
        },
        "trusted": true,
        "id": "h-h-U73qOSoX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model,train_dataloader,val_dataloader,epoch,optimizer,save_dir):\n",
        "    model =model.to(device)\n",
        "    loss_ls = []\n",
        "    model.train()\n",
        "    for i in range(epoch):\n",
        "        \n",
        "        for batch,(x,y) in enumerate(train_dataloader):\n",
        "            x,y = x.to(device) ,y.to(device)\n",
        "            logits = model(x)\n",
        "            loss = F.cross_entropy(logits,y)\n",
        "            loss_ls.append( loss.item() )\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "            if batch % 50 == 0:\n",
        "                loss = loss.item()\n",
        "                print(f\"------------train_loss: {loss:>7f}------------\")\n",
        "        \n",
        "        correct = 0\n",
        "        for batch,(x,y) in enumerate(val_dataloader):\n",
        "            x,y = x.to(device) ,y.to(device)\n",
        "            logits = model(x)\n",
        "            y_pre = logits.argmax(dim=-1)         \n",
        "            correct += torch.eq(y_pre,y).sum().item()\n",
        "            \n",
        "        correct = correct/len(val_dataloader.dataset)\n",
        "        print(f\"corect is {correct:2f}\")\n",
        "        \n",
        "        torch.save({\n",
        "            \"model_weight\":model.state_dict(),\n",
        "            \"optimizer\":optimizer.state_dict(),\n",
        "            \"loss\":loss_ls,\n",
        "            \"epoch\":epoch\n",
        "        },f'{save_dir}/epoch-{i}.ckpt')\n",
        "        \n",
        "        \n",
        "        \n",
        "    "
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-26T12:21:20.426730Z",
          "iopub.execute_input": "2022-02-26T12:21:20.426993Z",
          "iopub.status.idle": "2022-02-26T12:21:20.437558Z",
          "shell.execute_reply.started": "2022-02-26T12:21:20.426965Z",
          "shell.execute_reply": "2022-02-26T12:21:20.436631Z"
        },
        "trusted": true,
        "id": "5QiqjVhrOSoY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(model,test_dir,output_dir):\n",
        "    test_data = pd.read_csv(test_dir)\n",
        "    x= torch.from_numpy(np.array(test_data)).to(torch.float)\n",
        "    bs,n = x.shape\n",
        "    w = h = int(np.sqrt(n))\n",
        "    x = rearrange(x, 'bs (w h) -> bs 1 w h',w = w,h = h)\n",
        "    x = rearrange(x,'bs 1 w h -> bs 1 1 w h')\n",
        "    \n",
        "    \n",
        "    model = model.to(device)\n",
        "    x = x.to(device)\n",
        "    y_pre_ls =[]\n",
        "    for i in range(x.shape[0]):\n",
        "        logits = model(x[i])\n",
        "        y_pre = logits.argmax(dim=-1)\n",
        "        y_pre_ls.append((i,y_pre.item()))\n",
        "    with open(output_dir,'w+') as f:\n",
        "        f.write(f'ImageId,Label\\n')\n",
        "        for index,y in y_pre_ls:\n",
        "            f.write(f'{index+1},{y}\\n')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-26T14:10:47.994399Z",
          "iopub.execute_input": "2022-02-26T14:10:47.994692Z",
          "iopub.status.idle": "2022-02-26T14:11:09.737464Z",
          "shell.execute_reply.started": "2022-02-26T14:10:47.994645Z",
          "shell.execute_reply": "2022-02-26T14:11:09.736723Z"
        },
        "trusted": true,
        "id": "CuTq6CnFOSoY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(model,train_dataloader,val_dataloader,30,optimizer,\"/kaggle/working\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "XIdh0beNOSoY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict(model,\"../input/digit-recognizer/test.csv\",\"/kaggle/working/result.csv\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-26T12:24:41.802846Z",
          "iopub.execute_input": "2022-02-26T12:24:41.803399Z",
          "iopub.status.idle": "2022-02-26T12:25:03.121189Z",
          "shell.execute_reply.started": "2022-02-26T12:24:41.803358Z",
          "shell.execute_reply": "2022-02-26T12:25:03.120387Z"
        },
        "trusted": true,
        "id": "gXMQtAnQOSoY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = pd.read_csv(\"../input/digit-recognizer/test.csv\")\n",
        "x= torch.from_numpy(np.array(test_data)).to(torch.float)\n",
        "bs,n = x.shape\n",
        "w = h = int(np.sqrt(n))\n",
        "x = rearrange(x, 'bs (w h) -> bs 1 w h',w = w,h = h)\n",
        " \n",
        "plt.imshow(x.numpy()[0][0])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-26T12:08:36.587423Z",
          "iopub.execute_input": "2022-02-26T12:08:36.587673Z",
          "iopub.status.idle": "2022-02-26T12:08:38.531194Z",
          "shell.execute_reply.started": "2022-02-26T12:08:36.587645Z",
          "shell.execute_reply": "2022-02-26T12:08:38.530554Z"
        },
        "trusted": true,
        "id": "ylkZIWUDOSoZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(x.numpy()[5][0])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-26T06:18:40.624994Z",
          "iopub.execute_input": "2022-02-26T06:18:40.625281Z",
          "iopub.status.idle": "2022-02-26T06:18:40.826418Z",
          "shell.execute_reply.started": "2022-02-26T06:18:40.625248Z",
          "shell.execute_reply": "2022-02-26T06:18:40.825771Z"
        },
        "trusted": true,
        "id": "xpzRuPDSOSoZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test = pd.read_csv('/kaggle/input/digit-recognizer/test.csv')\n",
        "\n",
        "x = torch.from_numpy(np.array(test))\n",
        "bs,n = x.shape\n",
        "h =w = int(np.sqrt(n))\n",
        "x = rearrange(x, 'bs (w h) -> bs 1 w h',w = w,h = h)\n",
        "plt.imshow(x.numpy()[5][0])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-26T06:39:56.345723Z",
          "iopub.execute_input": "2022-02-26T06:39:56.346062Z",
          "iopub.status.idle": "2022-02-26T06:39:57.920107Z",
          "shell.execute_reply.started": "2022-02-26T06:39:56.346028Z",
          "shell.execute_reply": "2022-02-26T06:39:57.919058Z"
        },
        "trusted": true,
        "id": "AZRe-2IWOSoZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}